<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>duncanidaho.org – unstop</title>
  <link rel="stylesheet" href="/assets/main.css">
<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="/feed.xml"/>
</head>
<body>
<div class="page">
<header>
<div class="title">
<h1 class="title">unstop</h1>
</div>
<ul class="nav-header">
<li><a href="/">home</a></li>
<li><a href="/unstop.html">unstop</a></li>
<li><a href="/gallery.html">gallery</a></li>
<li><a href="/tasks.html">to do</a></li>
<li><a href="/style-test.html">style</a></li>
</ul>
<hr/>
</header>
<p><a href="./">Return to index</a></p>
<div class="h"><h1 id="unstop">unstop</h1><a aria-hidden="true" href="#unstop">[link]</a></div>
<p>I wrote a python script to perform neural style transfer. The project was a good learning experience, going in I knew almost nothing about python, neural networks or tensors. The code here is static and for demonstration purposes only, up to date source code is available <a href="https://github.com/duncanldaho/unstop">here</a>.</p>
<p>First the python modules need to be imported.</p>
<pre><code>import os
import tensorflow as tf
import tensorflow_hub as hub</code></pre>
<p>Then several functions are defined. This first function validates the user input to make sure a real file is chosen. In the future, I will also set it up to check the file extension. I’m not sure if it is best practice to use an <code>elif</code> statement that loops back into the original function, but so far it works.</p>
<pre><code>def extension_check(user_input):
    if os.path.isfile(user_input):
        return user_input
    else:
        print(&quot;Invalid input.&quot;)
        user_input = extension_check(input(&quot;Image path: &quot;))
        return user_input</code></pre>
<p>A function to resize the style image is necessary since the model was trained on an image that is 256x256.</p>
<pre><code>def resize(image):
    image = tf.image.resize(
        image, (256, 256), preserve_aspect_ratio=True, antialias=True
    )
    return image</code></pre>
<p>This next function decodes the JPEG data. The JPEG <code>uint8</code> data is cast to <code>float32</code>. Neurons can only process values between [0,1]. The maximum RGB value is 255, so they can be normalized by dividing by 255. These steps so far deliver a three dimensional array. An “empty” batch dimension is added since the model expects this data shape.</p>
<pre><code>def preprocess(image):
    image = tf.io.decode_jpeg(image, channels=3)
    image = tf.cast(image, tf.float32) / 255.0
    image = tf.expand_dims(image, axis=0)
    return image</code></pre>
<p>The last function performs the opposite of the previous function. It removes the batch dimension, coverts from [0,1] back to [0,255] RGB, casts the data from <code>float32</code> to <code>uint8</code>, and then encodes the data back into a JPEG.</p>
<pre><code>def postprocess(image):
    image = tf.squeeze(image, axis=None) * 255.0
    image = tf.cast(image, tf.uint8)
    image = tf.io.encode_jpeg(image, quality=95)
    return image</code></pre>
<p>Last of all is the actual code. It asks the user to specify the path to the images, utilizing the first function to make sure a real file is chosen. It loads the data, performs the functions in the appropriate order, and then finally runs the values (each image, decoded and transformed into tensors) through the tensorflow model.</p>
<pre><code>content_path = extension_check(input(&quot;Content image path: &quot;))
style_path = extension_check(input(&quot;Style image path: &quot;))
stylized_path = input(&quot;Write path: &quot;)

content = tf.io.read_file(content_path)
style = tf.io.read_file(style_path)

hub_module = hub.load(
    &quot;https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2&quot;
)

outputs = hub_module(preprocess(content), resize(preprocess(style)))
tf.io.write_file(stylized_path, postprocess(outputs))</code></pre>
<p>The tensorflow model is a bit of a mystery to me. It passes the data through the neural network and does some complicated maths to “extract” styles from one image and apply it to another. I want to stress this is the first python project I have worked on, I’m sure there are better or more optimized ways of performing similar style transfer.</p>
<p>A few things to look into:</p>
<ul>
<li>Casting to different data type and/or encoding into different file types</li>
<li>Best practices in python, finding ways to improve performance, rearranging the functions to be more intuitive</li>
<li>Setting the <code>preserve_aspect_ratio</code> and <code>antialias</code> options to true/false.</li>
<li>Replacing <code>tf.expand_dims</code> with <code>tf.reshape</code></li>
</ul>
<p>I would like to train my own models to gain a better understanding of neural networks. I think it would be extremely worthwhile to make a network for audio neural style transfer. All audio projects that I have come across use lossy means of passing the audio data to the neural network. After I get around to audio style transfer, A/V might be the next big project to work on.</p>
<div id="footer">
<hr />
<div class="footer">
<div>
© Duncan Idaho
</div>
<div>
Powered by <a href="https://untitled.vimuser.org/">untitled</a>
</div>
<div>
<a href="/sitemap.html">site map</a>
</div>
</div>
</div>
</div>
</body>
</html>
