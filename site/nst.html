<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>duncanidaho.org ‚Äì unstop</title>
  <link rel="stylesheet" href="/assets/main.css">
<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="/feed.xml"/>
</head>
<body>
<div class="page">
<header>
<div class="title">
<h1 class="title">unstop</h1>
</div>
<ul class="nav-header">
<li><a href="/">home</a></li>
<li><a href="/nst.html">unstop</a></li>
<li><a href="/gallery.html">gallery</a></li>
<li><a href="/tasks.html">to do</a></li>
<li><a href="/style-test.html">style</a></li>
</ul>
<hr/>
</header>
<p><a href="./">Return to index</a></p>
<div class="h"><h1 id="unstop">unstop</h1><a aria-hidden="true" href="#unstop">[link]</a></div>
<p>I wrote a python script to perform neural style transfer. The project was a good learning experience, I knew almost nothing about python, neural networks or tensors. The code here is static and for demonstration purposes only, up to date source code is available <a href="https://github.com/duncanldaho/unstop">here</a>.</p>
<p>First the python modules need to be imported.</p>
<pre><code>import os
import tensorflow as tf
import tensorflow_hub as hub</code></pre>
<p>Then several functions are defined. This first function validates the user input to make sure a real file is chosen. I‚Äôm not sure if it is ‚Äúbest practice‚Äù to use an <code>elif</code> statement that loops back into the original function, but it works.</p>
<pre><code>def extension_check(user_input):
    if os.path.isfile(user_input):
        return user_input
    else:
        print(&quot;Invalid input.&quot;)
        user_input = extension_check(input(&quot;Image path: &quot;))
        return user_input</code></pre>
<p>A function to resize the style image is necessary since the model was trained on an image that is 256x256.</p>
<pre><code>def resize(image):
    image = tf.image.resize(
        image, (256, 256), preserve_aspect_ratio=True, antialias=True
    )
    return image</code></pre>
<p>This next function decodes the JPEG data. A quick note on fixed and floating point numbers. JPEGs use an 8 bit unsigned integer: 256 values can be represented in base-2 with 8 bits, unsigned means those values can only be positive, and integers are of course whole numbers.</p>
<p><strong>Fixed point</strong> numbers are very <em>accurate</em>. They have a specific number of bits reserved for the integer <strong>and</strong> a specific number of bits reserved for the fraction. This comes at the cost of range, meaning you can represent fewer values with the same given number of bits.</p>
<p><strong>Floating point</strong> numbers are fundamentally different from fixed point, in that the decimal point ‚Äúfloats‚Äù. It can be placed anywhere relative to the significant digits of the number. This means values are approximated, less accurate but more precise. Floating point numbers are represented approximately, and a larger range can be represented with the same given number of bits.</p>
<p>The JPEG <code>uint8</code> data is cast to <code>float32</code>. The RGB values can be [0,255], so they are normalized by dividing by 255. Neurons can only process values between [0,1].</p>
<p>These steps so far deliver a three dimensional array. An ‚Äúempty‚Äù batch dimension is added since the model expects this data shape.</p>
<pre><code>def preprocess(image):
    image = tf.io.decode_jpeg(image, channels=3)
    image = tf.cast(image, tf.float32) / 255.0
    image = tf.expand_dims(image, axis=0)
    return image</code></pre>
<p>The last function performs the opposite of the previous function. It removes the batch dimension, coverts from [0,1] back to [0,255] RGB, casts the data from <code>float32</code> to <code>uint8</code>, and then encodes the data back into a JPEG file.</p>
<pre><code>def postprocess(image):
    &quot;&quot;&quot;Remove batch dim., convert to RGB, cast to uint8, encode JPEG data.&quot;&quot;&quot;
    image = tf.squeeze(image, axis=None) * 255.0
    image = tf.cast(image, tf.uint8)
    image = tf.io.encode_jpeg(image, quality=95)
    return image</code></pre>
<p>Last of all is the actual code. It asks the user to specify the path to the images, utilizing the first function to make sure a real file is chosen. It loads the data, performs the functions in the appropriate order, and then finally runs the two sets of data (each image) through the tensorflow model.</p>
<pre><code>content_path = extension_check(input(&quot;Content image path: &quot;))
style_path = extension_check(input(&quot;Style image path: &quot;))
stylized_path = input(&quot;Write path: &quot;)

content = tf.io.read_file(content_path)
style = tf.io.read_file(style_path)

hub_module = hub.load(
    &quot;https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2&quot;
)

outputs = hub_module(preprocess(content), resize(preprocess(style)))
tf.io.write_file(stylized_path, postprocess(outputs))</code></pre>
<p>The tensorflow model is a bit of a mystery to me. It passes the data through the neural network and does some complicated maths to ‚Äúextract‚Äù styles from one image and add them to another.</p>
<p>A few things to look into:</p>
<ul>
<li>Casting to different data type and/or encoding into different file types</li>
<li>Best practices in python, finding ways to improve performance, rearranging the functions to be more intuitive</li>
<li>Setting the <code>preserve_aspect_ratio</code> and <code>antialias</code> options to true/false.</li>
<li>Replacing <code>tf.expand_dims</code> with <code>tf.reshape</code></li>
</ul>
<p>I would like to train my own models to gain a better understanding of neural networks. I think it would be extremely worthwhile to make a network for audio neural style transfer. All audio projects that I have come across use lossy means of passing the audio data to the neural network. After I get around to audio style transfer, A/V might be the next big project to work on.</p>
<div id="footer">
<hr />
<div class="footer">
<div>
üÑØ Duncan Idaho
</div>
<div>
Powered by <a href="https://untitled.vimuser.org/">untitled</a>
</div>
<div>
<a href="/sitemap.html">site map</a>
</div>
</div>
</div>
</div>
</body>
</html>
